# -*- coding: utf-8 -*-
"""Regression: Diamond's Price.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/19twQRbE2zFo8qQcmSLAOC8SBvUhz-MRy

# 1. Business Understanding

## 1.1 Problem Statements

Berdasarakan kondisi yang telah diuraikan, perusahaan akan mengembangkan sebuah sistem prediksi harga diamonds untuk menjawab permasalahan berikut.  
1. Dari serangkaian fitur yang ada, fitur apa yang paling berpengaruh terhadap harga diamonds?
2. Berapa harga pasar diamonds dengan karakterisitik atau fitur tertentu?

## 1.2 Goals

Untuk menjawab pertanyaan tersebut, Anda akan membuat predictive modelling dengan goals sebagai berikut.  
1. Mengetahui fitur yang paling berkorelasi dengan harga diamonds.
2. Membuat model machine learning yang dapat memprediksi harga diamonds seakurat mungkin berdasarkan fitur-fitur yang ada.

## 1.3 Metodologi

Prediksi harga merupakan tujuannya. Harga merupakan variabel kontinu, oleh karena itu proyek kali ini masuk ke permasalahan regresi. Oleh karena itu, akan dibangun model regresi untuk memprediksi harga diamond.

## 1.4 Metrik

Untuk kasus regresi, beberapa metrik yang biasanya digunakan adalah Mean Squared Error (MSE) atau Root Mean Square Error (RMSE).

# 2. Data Understanding

## 2.1 Data Loading
"""

# Commented out IPython magic to ensure Python compatibility.
import numpy as np
import matplotlib.pyplot as plt
# %matplotlib inline
import pandas as pd
import seaborn as sns

url = 'https://raw.githubusercontent.com/tidyverse/ggplot2/main/data-raw/diamonds.csv'
diamonds = pd.read_csv(url)
diamonds

"""**Observasi**  
Output kode diatas memberikan informasi sebagai berikut:
- Ada 53940 baris data
- Terdapat 10 kolom fitur yaitu carat, cut, color, clarity, depth, table, price, x, y, z

## 2.2 Exploratory Data Analysis

### 2.2.1 Deskripsi Variabel

- price: harga dalam dolar Amerika Serikat ($) adalah fitur target.
- carat: mempresentasikan bobot dari diamonds (0.2 - 5.01), digunakan sebagai ukuran dari batu pertama dan perhiasan.
- cut: mempresentasikan kualitas pemotongan diamonds (Fair, Good, Very Good, Premium, and Ideal).
- color: mempresentasikan warna, dari J (paling buruk) ke D (yang terbaik).
- clarity: mempresentasikan seberapa jernih diamonds (I1 (paling buruk), SI1, SI2, VS1, VS2, VVS2, VVS1, IF(terbaik)).
- x: mempresentasikan panjang diamonds dalam mm (0-10.74).
- y: merepresentasikan lebar diamonds dalam mm (0-58.9).
- z: merepresentasikan kedalaman diamonds dalam mm (0-31.8).
- depth: merepresentasikan z/mean(x, y) = 2 * z/(x + y) --- (43 - 79).
- table: merepresentasikan lebar bagian atas berlian relatif terhadap titik terlebar (43 - 95)
"""

diamonds.info()

"""Dari output terlihat bahwa:
- Terdapat 3 kolom dengan tipe object, yaitu cut, color, dan clarity. Kolom ini merupakan categorical features (non-numerik).
- Terdapat 6 kolom numerik dengan tipe data float64 yaitu: carat, depth, table, x, y, dan z. Ini merupakan fitur numerik yang merupakan hasil pengurukuran secara fisik.
- Terdapat 1 kolom numeri dengan tipe data int64, yaitu price. Kolom ini merupakan target fitur kita.
"""

diamonds.describe()

"""### 2.2.2 Missing Value"""

x = (diamonds.x == 0).sum()
y = (diamonds.y == 0).sum()
z = (diamonds.z == 0).sum()

print(f"Nilai 0 pada variabel ada:\nx: {x}\ny: {y}\nz: {z}")

diamonds.loc[(diamonds.z == 0)]

"""Observasi:
- Seluruh data bernilai 0 pada dimensi x dan y juga memiliki nilai 0 pada dimensi Z.  
- 20 sampel missing value merupakan jumlah yang kecil jika dibandingkan dengan jumlah total sampel yaitu 53.940. Jika 20 sampel ini dihapus, tidak akan menjadi masalah yang signifikan.
"""

diamonds = diamonds.loc[(diamonds[['x', 'y', 'z']] != 0).all(axis=1)]
diamonds.shape

diamonds.describe()

"""### 2.2.3 Menangani Outliers

**Carat**
"""

sns.boxplot(x=diamonds.carat)

"""**Fitur Table**"""

sns.boxplot(x=diamonds.table)

"""**Fitur x**"""

sns.boxplot(x=diamonds.x)

"""Observasi:  
- Pada beberapa fitur numerik diatas terdapat outliers. Hal tersebut bisa dilihat dari nilai apa pun yang berada di luar batas diangaap outlier

Batas bawah = Q1 - 1.5 * IQR  
Batas atas = Q3 + 1.5 * IQR
"""

Q1 = diamonds.quantile(0.25)
Q3 = diamonds.quantile(0.75)
IQR = Q3 - Q1

diamonds = diamonds[~((diamonds<(Q1-1.5*IQR))|(diamonds>(Q3+1.5*IQR))).any(axis=1)]
diamonds.shape

diamonds

sns.boxplot(x=diamonds.table)

"""### 2.2.4 Univariate Analysis"""

numerical_features = ['price', 'carat', 'depth', 'x', 'y', 'z']
categorical_features = ['cut', 'color', 'clarity']

"""#### **Categorical Features**

Fitur Cut
"""

feature = categorical_features[0]
count = diamonds[feature].value_counts()
percentage = 100*diamonds[feature].value_counts(normalize=True)
df_ = pd.DataFrame({'jumlah':count, 'persentase':percentage.round(2)})
print(df_)
count.plot(kind='bar', title=feature)

"""Terdapat 5 kategori pada fitur Cut, Dari data persentase dapat disimpulkan bahwa lebih dari 60% sampel merupakan diamonds tipe grade tinggi, yaitu grade ideal dan premium.

Fitur Color
"""

feature = categorical_features[1]
count = diamonds[feature].value_counts()
percent = diamonds[feature].value_counts(normalize=True)*100
df_ = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(2)})
print(df_)
count.plot(kind='bar', title=feature)

"""Berdasarkan deskripsi variabel, urutan kategori warna dari yang paling buruk ke yang paling bagus adalah J, I, H, G, F, E, dan D. Dari grafik diatas, dapat kita simpulkan bahwa sebagian besar grade berapa pada grade menengah, yaitu G, F, H

Fitur Clarity
"""

feature = categorical_features[2]
count = diamonds[feature].value_counts()
percent = 100*diamonds[feature].value_counts(normalize=True)
df_ = pd.DataFrame({'jumlah sampel':count, 'persentase':percent.round(2)})
print(df_)
count.plot(kind='bar', title=feature)

"""Berdasarkan informasi dari deskripsi variabel, fitur Clarity terdiri dari 8 kategori dari paling buruk ke yang paling baik, yaitu: I1, SI1, SI2, VS2, VS1, VVS2, VVS1, dan IF. Dari grafik diatas dapat disimpulkan bahwa sebagian besar merupakan grade rendah. yaitu SI1, S12, VS2.

#### Numerical Features
"""

diamonds.hist(bins=50, figsize=(30, 15))
plt.show()

"""- Peningkatan harga diamond sebanding dengan penurunan jumlah sampel.
- Rentang harga diamonds cukup tinggi yaitu skala ratusan dolar amerika hingga sekitar USD11800
- Setengah harga berlian dibawah USD2500
- Distribusi harga miring ke kanan (right-skewed). Hal ini akan berimplikasi pada model.

### 2.2.5 Multivariate Analysis

#### Categorical Features
"""

for col in categorical_features:
    sns.catplot(x=col, y='price', kind='bar', dodge=False, height=4, aspect=3, data=diamonds, palette='Set3')
    plt.title(f"Rata-rata 'price' Relatif terhadap - {col}")

"""Dengan mengamati rata-rata harga relatif terhadap fitur kategorik di atas, kita memperoleh insight sebagai berikut.  
- pada fitur cut, rata-rata harga cenderung mirip. Rentangnya berada antara 3500 hingga 4500. Grade tertinggi yaitu grade ideal memiliki harga rata-rata terendah diantara grade lainnya. Sehingga, fitur cut memiliki pengaruh atau dampak yang kecil terhadap rata-rata harga.
- Pada fitur 'color', semakin rendah grade warna, harga diamonds justru semakin tinggi. Dari sini dapat disimpulkan bahwa warna memiliki pengaruh yang rendah terhadap harga.
Berdasarkan deskripsi variabel, urutan kategori warna dari yang paling buruk ke yang paling bagus adalah J, I, H, G, F, E, dan D.
- pada fitur 'clarity', secara umum, diamond dengan grade lebih rendah, memiliki harga yang lebih tinggi. Hal ini dapat disimplkan bahwa kejernihan / clarity memiliki pengaruh yang rendah terhadap harga.
- Fitur kategori, memiliki pengaruh yang rendah terhadap harga.

#### Numerical Features
"""

plt.figure(figsize=(8, 8))
corr = diamonds.corr().round(2)

sns.heatmap(data=corr, annot=True, cmap='coolwarm')
plt.title("Correlation Matrix Fitur Numerik", size=30)

"""Korelasi fitur carat, x, y, dan z memiliki skor korelasi yang besar (>= 0.9) dengan fitur target 'price'. Artinya fitur price berkorelasi tinggi dengan keempat fitur tsb. Sementara itu, fitur 'depth' memiliki korelasi yang sangat kecil (0.04). Sehingga, fitur tersebut dapat di drop."""

diamonds.drop(['depth'], inplace=True, axis=1)

diamonds.columns

"""## 2.3 Data Preparation

### 2.3.1 Encoding fitur kategori
"""

from sklearn.preprocessing import OneHotEncoder
diamonds = pd.concat([diamonds, pd.get_dummies(diamonds[['cut', 'color', 'clarity']])], axis=1)
diamonds.drop(columns=['cut', 'color', 'clarity'], inplace=True)
diamonds.head()

"""### 2.3.2 Reduksi Dimensi dengan PCA"""

sns.pairplot(diamonds[['x', 'y', 'z']])

"""Ketiga fitur diatas memiliki korelasi yang tinggi dan memiliki informasi yang sama yaitu ukuran diamonds."""

from sklearn.decomposition import PCA
pca = PCA(n_components=3, random_state=42)
pca.fit(diamonds[['x', 'y', 'z']])
princ_comp = pca.transform(diamonds[['x', 'y', 'z']])

pca.explained_variance_ratio_.round(3)

"""Arti output diatas adalah 99.8% informasi pada ketiga fitur x, y, z terdapat PC pertama. Sedangkan sisanya, sebesar 0.2% dan 0.1% terdapat ada PC kedua dan ketiga. Berdasarkan hasil ini, kita akan mereduksi fitur (dimensi) dan hanya mempertahankan PC pertama saja. PC pertama ini akan menjadi fitur dimensi atau ukuran berlian menggantikan ketiga fitur diberi nama 'dimension'."""

pca = PCA(n_components=1, random_state=42)
pca.fit(diamonds[['x', 'y', 'z']])
diamonds['dimension'] = pca.transform(diamonds.loc[:, ('x','y','z')]).flatten()
diamonds.drop(['x','y','z'], inplace=True, axis=1)

diamonds

"""### 2.3.3 Train-Test-Split"""

from sklearn.model_selection import train_test_split
X = diamonds.drop(['price'], axis=1)
y = diamonds['price']

X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.2)

"""### 2.3.4 Standarisasi"""

from sklearn.preprocessing import StandardScaler

numerical_features = ['carat', 'table', 'dimension']
scaler = StandardScaler()
scaler.fit(X_train[numerical_features])
X_train[numerical_features] = scaler.transform(X_train.loc[:, numerical_features])
X_train[numerical_features].head()

X_train[numerical_features].describe().round(4)

diamonds.head()

"""# Model Development"""

models_df = pd.DataFrame(index=['train_mse', 'test_mse'], columns=['RandomForest', 'Boosting'])

from sklearn.ensemble import RandomForestRegressor
from sklearn.metrics import mean_squared_error

RandomForest = RandomForestRegressor(n_estimators=100, max_depth=32, random_state=42, n_jobs=-1)
RandomForest.fit(X_train, y_train)

models_df.loc['train_mse','RandomForest'] = mean_squared_error(y_pred=RandomForest.predict(X_train), y_true=y_train)

"""## 3.3 Boosting Algorithm"""

from sklearn.ensemble import AdaBoostRegressor

boosting = AdaBoostRegressor(learning_rate=0.01, random_state=42)
boosting.fit(X_train, y_train)
models_df.loc['train_mse', 'Boosting'] = mean_squared_error(y_pred=boosting.predict(X_train), y_true=y_train)

"""# Evaluasi Model

Menggunakan Mean Squared Error (MSE).
"""

scaler = StandardScaler()
scaler.fit(X_test[numerical_features])
X_test.loc[:, numerical_features] = scaler.transform(X_test[numerical_features])

mse = pd.DataFrame(columns=['train', 'test'], index=['RandomForest','Boosting'])
model_dictionary = {'RandomForest': RandomForest, 'Boosting': boosting}

for name, model in model_dictionary.items():
    mse.loc[name, 'train'] = mean_squared_error(y_true=y_train, y_pred=model.predict(X_train))*1e-3
    mse.loc[name, 'test'] = mean_squared_error(y_true=y_test, y_pred=model.predict(X_test))*1e-3

mse

fig, axes = plt.subplots()
mse.sort_values(by='test', ascending=False).plot(kind='barh', ax=axes, zorder=3)
axes.grid()

"""Berdasarkan grafik diatas, model Random Forest memberikan nilai eror yang paling kecil. Sedangkan model dengan algoritma Boosting memiliki eror yang paling besar."""